{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4073f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir -> c:\\Users\\vasilauskas\\GitHub\\EV-Transition\n",
      "Expecting CSVs in -> c:\\Users\\vasilauskas\\GitHub\\EV-Transition\\data\\interim\n",
      "Segment series shape: (240, 4)\n",
      "Stage series shape  : (72, 3)\n",
      "Segment years: 2001–2024\n",
      "Stage years  : 2001–2024\n",
      "Saved: c:\\Users\\vasilauskas\\GitHub\\EV-Transition\\reports\\figures\\mi_qcew_segment_employment_trends.png\n",
      "Saved: c:\\Users\\vasilauskas\\GitHub\\EV-Transition\\reports\\figures\\mi_qcew_stage_employment_trends.png\n"
     ]
    }
   ],
   "source": [
    "# Michigan QCEW Employment Trends (2001–2024)\n",
    "#\n",
    "# This notebook visualizes employment time series for the ten supply-chain segments\n",
    "# and three stages using the BLS QCEW data (2001–2024).\n",
    "# The aggregates are generated by scripts/process_mi_qcew_segments.py and\n",
    "# stored under data/interim/.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def find_repo_root(markers=(\"data\", \"scripts\")) -> Path:\n",
    "    here = Path.cwd()\n",
    "    for p in (here, *here.parents):\n",
    "        if all((p / m).exists() for m in markers):\n",
    "            return p\n",
    "    return here  # fallback: current directory\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "os.chdir(REPO_ROOT)  # ensure all relative paths are from repo root\n",
    "print(\"Working dir ->\", Path.cwd())\n",
    "\n",
    "DATA_INTERIM = REPO_ROOT / \"data\" / \"interim\"\n",
    "FIG_DIR = REPO_ROOT / \"reports\" / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Expecting CSVs in ->\", DATA_INTERIM)\n",
    "\n",
    "# --- Optional: use seaborn for nicer defaults if available ---\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_theme(context=\"talk\", style=\"whitegrid\")\n",
    "except Exception:\n",
    "    # Fall back to matplotlib defaults if seaborn isn't installed\n",
    "    pass\n",
    "\n",
    "\n",
    "SEGMENT_CSV = DATA_INTERIM / \"mi_qcew_segment_employment_timeseries.csv\"\n",
    "STAGE_CSV   = DATA_INTERIM / \"mi_qcew_stage_employment_timeseries.csv\"\n",
    "\n",
    "# ---- Helpers\n",
    "def require_exists(p: Path, label: str):\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing {label} file at {p}. \"\n",
    "            \"Generate it by running scripts/process_mi_qcew_segments.py\"\n",
    "        )\n",
    "\n",
    "def validate_columns(df: pd.DataFrame, required: list, df_name: str):\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"{df_name} is missing required column(s): {missing}\\n\"\n",
    "            f\"Columns found: {sorted(df.columns.tolist())}\"\n",
    "        )\n",
    "\n",
    "def coerce_year(df: pd.DataFrame, year_col: str = \"year\", min_year: int = 2001, max_year: int = 2024):\n",
    "    # Convert to numeric, drop rows with invalid years, clip to range\n",
    "    df[year_col] = pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[year_col]).copy()\n",
    "    df[year_col] = df[year_col].astype(int)\n",
    "    df = df[(df[year_col] >= min_year) & (df[year_col] <= max_year)].copy()\n",
    "    return df\n",
    "\n",
    "def maybe_annualize(df: pd.DataFrame, group_cols: list, value_col: str):\n",
    "    \"\"\"If there are multiple rows per year (e.g., quarterly), annualize by summing.\"\"\"\n",
    "    checks = df.groupby(group_cols + [\"year\"]).size()\n",
    "    if (checks > 1).any():\n",
    "        df = (\n",
    "            df.groupby(group_cols + [\"year\"], as_index=False)[value_col]\n",
    "            .sum()\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# ---- Load\n",
    "require_exists(SEGMENT_CSV, \"segment timeseries\")\n",
    "require_exists(STAGE_CSV, \"stage timeseries\")\n",
    "\n",
    "segment_ts = pd.read_csv(SEGMENT_CSV)\n",
    "stage_ts   = pd.read_csv(STAGE_CSV)\n",
    "\n",
    "# ---- Validate expected columns\n",
    "# Expected column names (adjust here if your pipeline uses slightly different labels)\n",
    "SEGMENT_REQUIRED = [\"segment_id\", \"segment_label\", \"year\", \"employment_qcew\"]\n",
    "STAGE_REQUIRED   = [\"stage\", \"year\", \"employment_qcew\"]\n",
    "\n",
    "validate_columns(segment_ts, SEGMENT_REQUIRED, \"segment_ts\")\n",
    "validate_columns(stage_ts, STAGE_REQUIRED, \"stage_ts\")\n",
    "\n",
    "# ---- Clean & standardize\n",
    "segment_ts = coerce_year(segment_ts, \"year\", 2001, 2024)\n",
    "stage_ts   = coerce_year(stage_ts, \"year\", 2001, 2024)\n",
    "\n",
    "# Drop any accidental duplicates\n",
    "segment_ts = segment_ts.drop_duplicates(SEGMENT_REQUIRED).copy()\n",
    "stage_ts   = stage_ts.drop_duplicates(STAGE_REQUIRED).copy()\n",
    "\n",
    "# If your inputs are quarterly/monthly, aggregate to annual totals\n",
    "segment_ts = maybe_annualize(segment_ts, [\"segment_id\", \"segment_label\"], \"employment_qcew\")\n",
    "stage_ts   = maybe_annualize(stage_ts, [\"stage\"], \"employment_qcew\")\n",
    "\n",
    "# Sort for plotting\n",
    "segment_ts = segment_ts.sort_values([\"segment_id\", \"year\"])\n",
    "stage_ts   = stage_ts.sort_values([\"stage\", \"year\"])\n",
    "\n",
    "# ---- Quick sanity prints\n",
    "print(\"Segment series shape:\", segment_ts.shape)\n",
    "print(\"Stage series shape  :\", stage_ts.shape)\n",
    "print(\"Segment years:\", f\"{segment_ts['year'].min()}–{segment_ts['year'].max()}\")\n",
    "print(\"Stage years  :\", f\"{stage_ts['year'].min()}–{stage_ts['year'].max()}\")\n",
    "\n",
    "# =========================\n",
    "# Segment-Level Employment\n",
    "# =========================\n",
    "# Employment totals (jobs) for each supply-chain segment. Values are summed across\n",
    "# the NAICS industries assigned to each segment.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "# Use matplotlib directly for reliability; seaborn lineplot also works if imported\n",
    "for name, g in segment_ts.groupby(\"segment_label\", sort=False):\n",
    "    ax.plot(g[\"year\"], g[\"employment_qcew\"], label=name)\n",
    "\n",
    "ax.set_ylabel(\"Employment (QCEW)\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_title(\"Michigan Employment by Supply-Chain Segment (QCEW, 2001–2024)\")\n",
    "ax.legend(title=\"Segment\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "fig.tight_layout()\n",
    "\n",
    "segment_fig_path = FIG_DIR / \"mi_qcew_segment_employment_trends.png\"\n",
    "fig.savefig(segment_fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(f\"Saved: {segment_fig_path}\")\n",
    "\n",
    "# =======================\n",
    "# Stage-Level Employment\n",
    "# =======================\n",
    "# Employment totals aggregated to Upstream, OEM, and Downstream stages.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for name, g in stage_ts.groupby(\"stage\", sort=False):\n",
    "    ax.plot(g[\"year\"], g[\"employment_qcew\"], label=name)\n",
    "\n",
    "ax.set_ylabel(\"Employment (QCEW)\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_title(\"Michigan Employment by Stage (QCEW, 2001–2024)\")\n",
    "ax.legend(title=\"Stage\")\n",
    "fig.tight_layout()\n",
    "\n",
    "stage_fig_path = FIG_DIR / \"mi_qcew_stage_employment_trends.png\"\n",
    "fig.savefig(stage_fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(f\"Saved: {stage_fig_path}\")\n",
    "\n",
    "# ---- Notes\n",
    "# - Segment aggregates use the NAICS-to-segment mapping in data/lookups/segment_assignments.csv.\n",
    "# - Stage totals are summed across all segments mapped to each stage (Upstream, OEM, Downstream).\n",
    "# - To refresh, rerun scripts/process_mi_qcew_segments.py before executing this notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4b_301p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
